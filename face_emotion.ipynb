{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Project Configuration\n",
    "class Config:\n",
    "    # Data Parameters\n",
    "    IMAGE_SIZE = (224, 224)\n",
    "    BATCH_SIZE = 32\n",
    "    NUM_CLASSES = 7  # Typical facial expressions: Happy, Sad, Angry, Surprise, Neutral, Disgust, Fear\n",
    "    \n",
    "    # Training Parameters\n",
    "    EPOCHS = 50\n",
    "    LEARNING_RATE = 1e-4\n",
    "    \n",
    "    # Paths\n",
    "    DATA_DIR = 'data/fer2013'\n",
    "    MODEL_SAVE_PATH = 'models/facial_expression_model.h5'\n",
    "    \n",
    "    # GPU Configuration\n",
    "    def configure_gpu():\n",
    "        gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "        if gpus:\n",
    "            try:\n",
    "                for gpu in gpus:\n",
    "                    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            except RuntimeError as e:\n",
    "                print(e)\n",
    "\n",
    "# Configure GPU if available\n",
    "Config.configure_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    @staticmethod\n",
    "    def load_fer2013_dataset(path):\n",
    "        \"\"\"\n",
    "        Load FER2013 dataset\n",
    "        Returns X (images), y (labels)\n",
    "        \"\"\"\n",
    "        data = pd.read_csv(os.path.join(path, 'fer2013.csv'))\n",
    "        \n",
    "        # Split data into training, validation, and test\n",
    "        train_data = data[data['Usage'] == 'Training']\n",
    "        val_data = data[data['Usage'] == 'PublicTest']\n",
    "        test_data = data[data['Usage'] == 'PrivateTest']\n",
    "        \n",
    "        def parse_data(df):\n",
    "            images = df['pixels'].apply(lambda x: np.fromstring(x, sep=' '))\n",
    "            images = np.vstack(images.values) / 255.0  # Normalize\n",
    "            images = images.reshape(-1, 48, 48, 1)\n",
    "            labels = df['emotion'].values\n",
    "            return images, labels\n",
    "        \n",
    "        X_train, y_train = parse_data(train_data)\n",
    "        X_val, y_val = parse_data(val_data)\n",
    "        X_test, y_test = parse_data(test_data)\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test)\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_data_generators(X_train, y_train, X_val, y_val, config):\n",
    "        \"\"\"\n",
    "        Create data generators with augmentation\n",
    "        \"\"\"\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest'\n",
    "        )\n",
    "        \n",
    "        val_datagen = ImageDataGenerator()\n",
    "        \n",
    "        # Resize images to match transfer learning model input\n",
    "        X_train_resized = tf.image.resize(X_train, config.IMAGE_SIZE)\n",
    "        X_val_resized = tf.image.resize(X_val, config.IMAGE_SIZE)\n",
    "        \n",
    "        # Repeat grayscale image across 3 channels for transfer learning model\n",
    "        X_train_rgb = tf.repeat(X_train_resized, repeats=3, axis=-1)\n",
    "        X_val_rgb = tf.repeat(X_val_resized, repeats=3, axis=-1)\n",
    "        \n",
    "        train_generator = train_datagen.flow(\n",
    "            X_train_rgb, y_train, \n",
    "            batch_size=config.BATCH_SIZE, \n",
    "            shuffle=True\n",
    "        )\n",
    "        \n",
    "        val_generator = val_datagen.flow(\n",
    "            X_val_rgb, y_val, \n",
    "            batch_size=config.BATCH_SIZE, \n",
    "            shuffle=False\n",
    "        )\n",
    "        \n",
    "        return train_generator, val_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FacialExpressionModel:\n",
    "    @staticmethod\n",
    "    def build_model(config):\n",
    "        \"\"\"\n",
    "        Create transfer learning model using MobileNetV2\n",
    "        \"\"\"\n",
    "        # Base model\n",
    "        base_model = MobileNetV2(\n",
    "            weights='imagenet', \n",
    "            include_top=False, \n",
    "            input_shape=(*config.IMAGE_SIZE, 3)\n",
    "        )\n",
    "        \n",
    "        # Freeze base model layers\n",
    "        base_model.trainable = False\n",
    "        \n",
    "        # Add custom classification head\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(512, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        \n",
    "        # Output layer\n",
    "        output = Dense(\n",
    "            config.NUM_CLASSES, \n",
    "            activation='softmax', \n",
    "            name='expression_output'\n",
    "        )(x)\n",
    "        \n",
    "        model = Model(inputs=base_model.input, outputs=output)\n",
    "        \n",
    "        # Compile model\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=config.LEARNING_RATE)\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    @staticmethod\n",
    "    def train(config):\n",
    "        # Load dataset\n",
    "        (X_train, y_train), (X_val, y_val), (X_test, y_test) = DataProcessor.load_fer2013_dataset(config.DATA_DIR)\n",
    "        \n",
    "        # Create data generators\n",
    "        train_generator, val_generator = DataProcessor.create_data_generators(\n",
    "            X_train, y_train, X_val, y_val, config\n",
    "        )\n",
    "        \n",
    "        # Build model\n",
    "        model = FacialExpressionModel.build_model(config)\n",
    "        \n",
    "        # Callbacks\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', \n",
    "            patience=10, \n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "            config.MODEL_SAVE_PATH, \n",
    "            save_best_only=True\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            validation_data=val_generator,\n",
    "            epochs=config.EPOCHS,\n",
    "            callbacks=[early_stopping, model_checkpoint]\n",
    "        )\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        X_test_resized = tf.image.resize(X_test, config.IMAGE_SIZE)\n",
    "        X_test_rgb = tf.repeat(X_test_resized, repeats=3, axis=-1)\n",
    "        \n",
    "        test_loss, test_accuracy = model.evaluate(X_test_rgb, y_test)\n",
    "        print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "        \n",
    "        # Detailed Classification Report\n",
    "        y_pred = model.predict(X_test_rgb)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "        \n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred_classes, \n",
    "            target_names=['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']))\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(y_test, y_pred_classes)\n",
    "        plt.figure(figsize=(10,8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', \n",
    "            xticklabels=['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral'],\n",
    "            yticklabels=['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral'])\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('results/confusion_matrix.png')\n",
    "        plt.close()\n",
    "        \n",
    "        return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    trained_model, training_history = ModelTrainer.train(Config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FacialExpressionInference:\n",
    "    def __init__(self, model_path, config):\n",
    "        self.model = tf.keras.models.load_model(model_path)\n",
    "        self.config = config\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        self.expressions = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "    \n",
    "    def detect_and_predict(self, frame):\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Detect faces\n",
    "        faces = self.face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "        \n",
    "        for (x, y, w, h) in faces:\n",
    "            # Extract face ROI\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            \n",
    "            # Preprocess for model\n",
    "            roi_resized = cv2.resize(roi_gray, (48, 48))\n",
    "            roi_normalized = roi_resized / 255.0\n",
    "            roi_expanded = np.expand_dims(roi_normalized, axis=[0, -1])\n",
    "            \n",
    "            # Resize to match transfer learning model input\n",
    "            roi_rgb = np.repeat(cv2.resize(roi_expanded[0], self.config.IMAGE_SIZE), 3, axis=-1)\n",
    "            roi_rgb = np.expand_dims(roi_rgb, axis=0)\n",
    "            \n",
    "            # Predict\n",
    "            prediction = self.model.predict(roi_rgb)\n",
    "            emotion_idx = np.argmax(prediction)\n",
    "            emotion = self.expressions[emotion_idx]\n",
    "            confidence = prediction[0][emotion_idx]\n",
    "            \n",
    "            # Draw rectangle and text\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            cv2.putText(frame, f'{emotion}: {confidence:.2f}', \n",
    "                        (x, y-10), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, \n",
    "                        (36,255,12), 2)\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def real_time_detection(self):\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Flip frame for natural view\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            \n",
    "            # Detect and predict\n",
    "            processed_frame = self.detect_and_predict(frame)\n",
    "            \n",
    "            # Display\n",
    "            cv2.imshow('Facial Expression Recognition', processed_frame)\n",
    "            \n",
    "            # Exit condition\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    inference = FacialExpressionInference(\n",
    "        model_path=Config.MODEL_SAVE_PATH, \n",
    "        config=Config\n",
    "    )\n",
    "    inference.real_time_detection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
